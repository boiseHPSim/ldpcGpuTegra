% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}

% *** CITATION PACKAGES ***
%
\usepackage{cite}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
 \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi

% *** MATH PACKAGES ***
%
\usepackage{mathtools}  
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabulary}
\usepackage{booktabs}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

\interdisplaylinepenalty=2500

% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic,algorithm}


% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}

% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi

% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}

%\usepackage{stfloats}

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{Heterogeneous LDPC Decoder Algorithm on ARM and GPU of Mobile Devices}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Roohollah Amiri}
\IEEEauthorblockA{Department of Electrical and\\Computer Engineering\\
Boise State University\\
Email: roohollahamiri@boisestate.edu}
\and
\IEEEauthorblockN{Hani Mehrpouyan}
\IEEEauthorblockA{Department of Electrical and\\Computer Engineering\\
Boise State University\\
Email: hanimehrpouyan@boisestate.edu}
%\and
%\IEEEauthorblockN{Inanc Senocak}
%\IEEEauthorblockA{Department of Mechanical Engineering\\
%Boise State University\\
%Email: senocak@boisestate.edu}
}

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}


Low density parity check (LDPC) codes have been extensively applied in mobile communication systems due to their excellent error correcting capabilities. However, their wide adoption has been hindered by the high complexity of the LDPC decoder. Although to date, dedicated hardware has been used to implement low latency LDPC decoders, recent advancements in the architecture of mobile processors has made it possible to develop software solutions. Here, unlike prior solutions that are based on either graphic processing units (GPUs) or advanced RISC machine (ARM) architectures, we propose a heterogeneous LDPC decoder that uses both the ARM and GPU processors of a mobile device to achieve efficient real-time decoding. The proposed solution is implemented on an NVIDIA development kit, where our results indicate that we can reduce the load on either the GPU or the ARM processor through the proposed heterogeneous structure, which in turn allows these resources to support other applications, simultaneously.


%Low density parity check (LDPC) codes have been extensively applied in mobile communication systems due to their excellent error correcting capabilities. However, the wide adoption of LDPC codes has been hindered by the high computational complexity of the LDPC decoder at the receiver. Although to date, dedicated hardware has been used to develop low latency LDPC decoders, recent advancements in the architecture of mobile processors has made it possible to develop software based solutions. Hence, there has been significant effort to develop low latency LDPC decoders via algorithm optimization and parallel implementation. Here, unlike prior solutions that are based on either graphic processing units (GPUs) or advanced RISC machine (ARM) architectures, we propose a heterogeneous LDPC decoder that uses both ARM and GPU processors of a mobile device to achieve efficient real-time decoding. The proposed solution has been implemented on an NVIDIA mobile development board, where our results indicate that we can reduce the load on either the GPU or the ARM processor through the proposed heterogeneous structure, which in turn allows the mobile device to support other applications. 

%Low density  parity check (LDPC) codes have been extensively applied to enhance the performance of mobile communication systems due to their enhanced error correction capabilities. However, the wide adoption of strong LDPC codes has been hindered by the high computational complexity of the LDPC decoder at the receiver. Although to date, dedicated hardware has been used to develop low latency LDPC decoders, recent advancements in the architecture of mobile processors has made it possible to develop software based LDPC decoders. Hence, there has been significant effort to design and develop low latency LDPC decoders by utilizing algorithm optimization and parallel implementation. 


%Recent improvements in mobile processors's architectures has made it exclusively reachable to have a real-time decoder based on a software solution. 

%Knowing this capability, low profile GPU based decoders have been introduced that are capable of reaching high throughput by low latency. On the other hand recently there has been some work that has used ARM NEON SIMD unit with promising throughput and latency. What this works miss is that a mobile processor that is used in a smart phone should support a lot of task and we can not allocate all resources to decoding prcesses. In this paper we propose a heterogeneous LDPC decoder that uses both ARM and GPU Processors of a mobile device to reach real-time effieciency. The different stages of decoder processes has been allocated to ARM and GPU based on an optimization solution. 


%With the wide usage and having computational intensivity of LDPC decoders, there has been a lot of effort to reduce decoder's complexity through algorithm optimization and parallel implementation. 


%for error correction in communication systems.  to  is an efficient way of communication and is being largely used in mobile communication. With the wide usage and having computational intensivity of LDPC decoders, there has been a lot of effort to reduce decoder's complexity through algorithm optimization and parallel implementation. Recent improvements in mobile processors's architectures has made it exclusively reachable to have a real-time decoder based on a software solution. Knowing this capability, low profile GPU based decoders has been introduced that are capable of reaching high throughput by low latency. On the other hand recently there has been some work that has used ARM NEON SIMD unit with promising throughput and latency. What this works miss is that a mobile processor that is used in a smart phone should support a lot of task and we can not allocate all resources to decoding prcesses. In this paper we propose a heterogeneous LDPC decoder that uses both ARM and GPU Processors of a mobile device to reach real-time effieciency. The different stages of decoder processes has been allocated to ARM and GPU based on an optimization solution. 


\end{abstract}

% no keywords

\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
% LDPC , Usages, Complexity
Originally proposed by Robert Gallager in 1962 \cite{art_gallager} and rediscovered by MacKay and Neal in 1996 \cite{art_macKay} Low Density Parity Check (LDPC) codes have been adopted by a wide range of applications including many communication standards such as WiFi (IEEE 802.11n), 10 Gigabit Ethernet (IEEE 802.3an), Long Term Evolution (LTE), and DVB-S2. Recently, Chung and Richardson \cite{art_shannon} showed that a class of LDPC codes can approach the Shannon limit to within 0.0045 dB. However, the error correcting strength of these codes comes at the cost of very high decoding complexity \cite{art_ldpc_cpu1}. Moreover, to date, there are no closed-form solutions to determine the performance of LDPC codes in various wireless channels and systems. Thus, performance evaluation is typically carried out via simulations on computers or dedicated hardwares \cite{art_memory_coalesced}.

% Initial implementation
Since LDPC decoding algorithms are computationally-intensive and need powerful computer architecture to result in low latency and high throughput, to date, most LDPC decoders are implemented using application-specific integrated circuits(ASIC) or field-programmable gate array (FPGA) circuits \cite{art_ldpc_OpenCl_1}. However, their high speed often comes at a price of high developement cost and low programming flexibility \cite{art_convolutional} and it is very challenging to design decoder hardware that supports various standards and multiple data rates \cite{art_cuda_openmp}. On the other hand, iterative LDPC decoding schemes based on the sum-product algorithm (SPA) can fully be parallelized, leading to high-speed decoding \cite{art_shannon}. For these reasons, designers have recently focused on software implementations of LDPC decoders on multi/many-core devices \cite{art_massively} to meet the performance requirements of current communication systems through Software Defined Radio (SDR). As in terms of multicore architectures, researchers have used CPUs \cite{art_cpu_gpu, art_ldpc_cpu0}, GPUs \cite{art_memory_coalesced, art_massively, art_optimize_0} and advanced RISC machine (ARM) \cite{art_ldpc_cpu0, art_neon} architectures to develop high throughput, low latency SDRs. 

%CPUs
In microarchitectures, increasing clock frequencies to obtain faster processing peorformance has reached the limits of silicon based architectures. Hence, to achieve gains in processing performance, other techniques based on parallel processing is being investigated \cite{art_ldpc_cpu1}. Todays' multicore architectures support Single Instruction Multiple Data (SIMD), Single Programm Multiple Data (SPMD) and Single Instruction Multiple Threads (SIMT). The general purpose multicore processors replicate a single core in a homogeneous way, typically with a x86 instruction set, and provide shared memory hardware mechanisms\cite{art_massively}. Such multi-core structures can be programmed at a high level by using different software technologies \cite{art_multicore_techs}. OpenMP \cite{art_openMp_book} provides an effective and relatively straightforward approach for programming general-purpose multicores. On the other hand newer microarchitectures are trying to provide larger SIMD units for vector processing like Streaming SIMD Extensions (SSE), Advanced Vector Extensions (AVX) and AVX2 \cite{art_intel_sse} on Intel Architectures. In \cite{art_ldpc_cpu1}, the authors have used Intel SSE/AVX2 SIMD units to effieciently implement a high throughput LDPC decoder. In \cite{art_cuda_openmp}, OpenMP is used to generate address patterns with parity check H-matrix.

%GPUs
Mainly due to the demands for visualization technology in the gaming industry, the performance of graphics processing units (GPUs) has significantly improved over the last decade. With many cores driven by a considerable memory bandwidth, recent GPUs are targeted for solving computationally intensive algorithms in a multithreaded and highly parallel fashion. Hence, researchers in the high-performance computing field are applying GPUs to general-purpose applications (GPGPU) \cite{art_gpu_0,art_cuda_openmp, art_memory_coalesced, art_ldpc_OpenCl, art_optimize_0, art_layered1}. Pertaining to the field of communication, researchers have used Compute Unified Device Architecture (CUDA) from NVIDIA \cite{website_cuda} and Open Computing Language (OpenCL) platforms to develop LDPC decoders on GPUs.

%ARMs and NEON
Due to large computing capacity of multicore devices, software based LDPC decoders have met the required throughputs of communication standards, although power consumption of x86 and GPU devices is incompatible with most of embedded systems \cite{art_neon}. To solve this issue, ARM-based SDR systems have been prposed in recent years \cite{art_neon, art_ldpc_cpu0, art_ldpc_OpenCl_1} with the goal to develop an SDR based LDPC decoder that provides high throughput and low latency on a low-power embedded system. The authors in \cite{art_neon} have used ARM processor's SIMD and SIMT programming models to implement a LDPC decoder that is based on parallel decoding of data frames. This approach allows reaching high throughput while maintaining low-latency. However, the proposed ARM based solution in \cite{art_neon}, is based on the assumption that the ARM processor is solely used for LDPC decoding and does not take advantage of the available GPU processing on mobile device. Since mobile devices need to support multiple applications, the resources on the ARM processor must be better managed and cannot be all dedicated to the LDPC decoder. Moreover, recent works in SDR LDPC embedded systems are missing the fact that today mobile devices have powerful CUDA enabled GPUs.

%Contributions
The contributions of this paper are twofold. First, it proposes an LDPC decoder for an embedded device which exploits ARM SIMD Units and GPU of the device together. This allows these resources to also support other applications on a mobile device. Second, as a consequence of this, by using the GPU of a mobile device, less memory from ARM processor is being used which is typically limited in an embedded system. The remainder of the paper is structured as follows. Section \ref{sec2} briefly  introduces the LDPC code family and its decoding algorithms. Then the proposed heterogeneous algorithm on embedded targets is described in Section \ref{sec3}. Finally, \ref{sec4} gives experimental results and some comparisons with other ARM implementations.

\section{LDPC codes and their Decoding Processes}\label{sec2}

% LDPC Codes
LDPC codes are a class of linear block codes with a very sparse parity check matrix called H-matrix. Their main advantage is that they provide a peformance which is very close to the channel capacity for a lot of different channels and linear time complex algorithms for decoding. Furthermore, they are suited for implementations that make heavy use of parallelism.

%representation
Basically there are two ways to represent LDPC codes. Like all linear block codes they can be described by their H-matrix, while they can be represented by a Tanner graph which is a bipartite graph. An LDPC graph consists of a set of variable nodes (VNs) , a set of check nodes (CNs), and a set of edges E. Each edge connects a variable node to a check node. For example, when the (i,j) element of an H-matrix is '1', the ith check node is connected to the jth variable node of the equivalent Tanner graph. Figure \ref{tanner} illustrate the equivalent Tanner graph for (10,5) LDPC code with H-matrix in \ref{H-matrix}.

\begin{equation}\label{H-matrix}
H=
  \begin{bmatrix}
    1 & 1 & 1 & 1 & 0 &0 &0 &0 &0 &0 \\
    1 & 0 & 0 & 0 & 1 &1 &1 &0 &0 &0 \\
    0 & 1 & 0 & 0 & 1 &0 &0 &1 &1 &0 \\
    0 & 0 & 1 & 0 & 0 &1 &0 &1 &0 &1 \\
    0 & 0 & 0 & 1 & 0 &0 &1 &0 &1 &1 \\
  \end{bmatrix}
\end{equation}

\begin{figure}[h]\label{tanner}
\begin{centering}
\includegraphics[scale=0.35]{tanner.pdf}
\caption[width=.3\textwidth]{An example of Tanner graph}
\end{centering}
\end{figure}

%Decoding
Many works as in \cite{art_massively, art_ldpc_cpu0,art_ldpc_OpenCl_1,art_gpu_0} focused on mapping LDPC decoders on multicore architectures. Most of these works are based on the standard two-phase message passing (TPMP) schedule described in \cite{art_massively}. This algorithm works in two phases. In the first phase, all the variable nodes send messages to their neighboring parity check nodes, and in the second phase the parity check nodes send messages to their neighboring variable nodes. Due to transcendental operations and relying of message passing algorithm to the estimation of noise standard deviation, in practice Min-Sum (MS) variants are prefered by designers \cite{art_neon}. This algorithm is provided in Algorithm 1.

\begin{algorithm}\label{algorithm1}
\renewcommand\thealgorithm{}
\caption{Flooding Min-Sum algorithm}
\begin{algorithmic}[1]
\STATE \textbf{Kernel 1:} Initialization
\FORALL{$m \in C, n \in V$}
%\IF{$H_{mn}==1$}
\STATE
$Lq_{nm}=0$%LP_n=\dfrac{2y_n}{\sigma^2}.$
%\ENDIF
\ENDFOR
\FORALL{$t=1 \rightarrow (iter\_max)$}
\STATE \textbf{Kernel 2:} LLR of message $CN_m$ to $BN_n$
\FORALL{$m \in C, n \in V$}
\STATE $\alpha_{nm} \triangleq sign(Lq_{nm}),$
\STATE $\beta_{nm} \triangleq \abs{Lq_{nm}},$
\STATE $Lr_{mn} = \prod\limits_{n' \in N(m)\backslash n} \alpha_{n'm} \min\limits_{n' \in N(m)\backslash n} \beta_{n'm}.$
\ENDFOR
\STATE \textbf{Kernel 3:} LLR of message $BN_n$ to $CN_m$
\FORALL{$m \in C, n \in V$}
\STATE $Lq_{nm} = LP_n + \sum\limits_{m' \in M(n)\backslash m} Lr_{m'n}.$
\ENDFOR  
\ENDFOR % End of Iter
\STATE \textbf{Kernel 4:} Hard decision from soft-values
\FORALL{$n \in V$}
\STATE $LQ_{n} = LP_n + \sum\limits_{m' \in M(n)} Lr_{m'n},$
\STATE $\forall n, \hat{c}=[LQ_n]>0.$
\ENDFOR
\end{algorithmic}
\addtocounter{algorithm}{-1}
\end{algorithm}

More efficient layered schedules, such horizontal layered-based decoding algorithm, allow updated imformation to be utilized more quickly in the algorithm, thus, speeding up the decoding\cite{art_layered0, art_layered1}. In fact, the H-matrix can be viewed as a layered graph that is decoded sequentially. The work in \cite{art_gpu_0} has applied a form of layered belief propogation to irregular LDPC codes to reach 2x faster convergence in a given error rate.By using this method they have reduced memory bits usage by 45-50\%. The layered decoding (Algorithm 2) can be summarized as follow: all values for the check node computations are computed using variable node massages linked to them. Once, a check node is calculated, the corresponding variable nodes are updated immediately after receiving massages. This process is repeated to the maximum number of iterations.
\begin{algorithm}\label{algorithm2}
\renewcommand\thealgorithm{}
\caption{Horizontal Layered Min-Sum algorithm}
\begin{algorithmic}
\STATE \textbf{Kernel 1:} Initialization
\FORALL{$m \in C, n \in V$}
\STATE
$Lr_{mn}=0$
\ENDFOR
\FORALL{$t=1 \rightarrow (iter\_max)$}
\STATE \textbf{Kernel 2:} Process each CN one after another
\FORALL{$m \in C$}
\FORALL{$n \in V$}
\STATE $\alpha_{nm} \triangleq sign(Lq_{nm}),$
\STATE $\beta_{nm} \triangleq \abs{Lq_{nm}},$
\STATE $Lr'_{mn} = \prod\limits_{n' \in N(m)\backslash n} \alpha_{n'm} \min\limits_{n' \in N(m)\backslash n} \beta_{n'm}.$ \STATE\COMMENT{$Lr'_{mn}$ is the new calculated massage to $BN_n$}
\ENDFOR
\ENDFOR
\FORALL{$n \in V$}
\STATE $LQ'_n=LQ_n-Lr_{mn}+Lr'_{mn}$
\ENDFOR
\ENDFOR % END Iteration
\STATE \textbf{Kernel 4:} Hard decision from soft-values
\FORALL{$n \in V$}
\STATE $\forall n, \hat{c}=[LQ_n]>0.$
\ENDFOR
\end{algorithmic}
\addtocounter{algorithm}{-1}
\end{algorithm}

In algorithm 1, TPMP, the kernels 2 and 3 are updated by seperate processing and passes to each other iteratively. It means that variable nodes update, will not start until all check nodes are updated. Consdering that, algorithm 2, horizontal layered decoding, is composed of a single loop kernel with some data dependencies between consecutive loop Iterations and in each Iteration, the horizontal layers are processed sequentially from the top to the bottom layer \cite{art_quasi}.

The major limitation of layered algorithm is its irregular memory access although it is composed of a single loop kernel composed to two sequential kernels in standard algorithms. To solve this irregular memory access, a data interleaving/deinterleaving process is used before and after the decoding process in \cite{art_gpu_0, art_neon}, which is used in the proposing algorithm too. In \cite{art_gpu_0}, the GPU decoder achieves high throughputs but its latency that goes beyond seconds makes it suitable for simulation purposes only. On the other hand, the ARM decoder proposed in \cite{art_neon} uses all computing resources (4 existing cores) for LDPC decoding and does not take advantage of GPU processing on mobile devices. This paper uses one single core of ARM and the GPU device of a mobile processor to implement a high throughput and low latency LDPC decoder. By using one core of the ARM processor, there will be extra processing power for other applications of a mobile device and less memory of ARM processor will be used for decoding. On the other hand, since the GPU and ARM of a mobile device are sitting on a same die, the latency issues in \cite{art_gpu_0} are improved.

\section{Parallel Frame Processing} \label{sec3}
The porposed LDPC decoder is implemented on Jetson TK1 SoCs which contains 4 Cortex-A15 processors. Each core includes a NEON SIMD unit. To achieve high throughput performance on such low-power embedded processors, the following programming model is exploited in the proposed LDPC decoder.

\begin{figure}[h]
\begin{centering}
\scalebox{0.4}{\includegraphics{structure.eps}}
\caption[width=.3\textwidth]{Proposed Setup for Heterogeneous LDPC decoding}
\label{fig_porposed_alg}
\end{centering}
\end{figure}

Typically, there are two ways to deliver messages in LDPC decoding. One is to use probabilities, and the other is to use log-likelihood ratios (LLRs). In general, using LLRs is favored since that allows us to replace expensive multiplication operations with inexpensive addition operations \cite{art_cuda_openmp}. So the host is in charge of Initialization of Check Nodes (CNS), Frame interleaving befor decoding and frame deinterleaving after decoding. From decoder point of view, host sends/receive data to/from the GPU device as the decoder. The GPU device is responsible for all CNs to Variable Nodes(VNs) computations that is done in one kernel (see figure \ref{fig_porposed_alg}). At the end of decoding, hard decision decodings are taken and decisions are sent back to the host.
SIMD programming model in host enables each processor core to interleave F frames in parallel with 8-bitxF the width in bits of SIMD unit. So there is C (number of host cores) set of F frame streams of data into GPU device. Each processor controls its own stream to GPU. On the GPU there are C similar kernel running. As long as the memory that is used in GPU is bigger than CxFx8-bits, there would be no problem in memory allocation. 



\section{Experimental Results} \label{sec4}

The experiments were carried out by decoding LDPC codes using NVIDIA Tegra K1 Socs. The programs compiled with GCC-4.8 and CUDA 6.5. The TK1 is composed of 4 cortex-A15 ARM processors and one NVIDIA Kepler "GK20a" GPU with 192 SM3.2 CUDA cores. The host platform uses a GNU/Linux kernel 3.10.40-gdacac96. 

\section{Conclusion}
The conclusion goes here.

\newpage

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ldpcGpuTegra_bibliography}



% that's all folks
\end{document}


